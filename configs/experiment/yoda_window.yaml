# @package _global_

defaults:
  - override /data: yoda_dataset
  - override /model: yoda
  - override /callbacks: default
  - override /trainer: ddp
  - override /paths: default

tags: ["yoda", "video_matching"]
train: True
test: False #True
seed: 1401
ckpt_path: null #logs/train/runs/2024-08-25_13-23-05/checkpoints/last.ckpt  # null
allow_tf32: True

paths:
  data_dir: /var/tmp/yoda3

callbacks:
  early_stopping:
    monitor: "train/loss"
    patience: 100
    mode: "min"
  model_checkpoint:
    monitor: "train/loss"
    mode: "min"
    save_last: True
    save_top_k: 1
    auto_insert_metric_name: False
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch_{epoch:03d}"
  model_summary:
    max_depth: 0

model:
  num_val_frames: 15
  test_nfe: 100
  plot: True

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.0001 #0.001
    weight_decay: 1e-5

  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    _partial_: true
    step_size: 2
    gamma: 0.9

trainer:
  devices: 4
  strategy: ddp_find_unused_parameters_true
  sync_batchnorm: True

  #limit_train_batches: 2
  limit_val_batches: 0 #2
  num_sanity_val_steps: 0
  #  min_epochs: 10
  max_epochs: 50

data:
  batch_size: 2
  frames_per_sample: 25
  #num_steps: 32
  num_workers: 15
#
logger:
  wandb:
    tags: ${tags}
    group: "test"
  aim:
    experiment: "test"
